{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cybersecurity Incident Classification using T5 Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "This notebook demonstrates the evaluation of a fine-tuned T5 transformer model for classifying cybersecurity incidents. The model takes detailed incident descriptions and classifies them into predefined categories and subcategories, helping security teams streamline their incident response process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, TrainerCallback\n",
    "from datasets import Dataset\n",
    "import pickle\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = pd.read_csv('./cleaned_dataset/cleaned_test_dataset.csv')\n",
    "\n",
    "# Load categories and subcategories lists\n",
    "with open(\"categories.pkl\", \"rb\") as file:\n",
    "    categories = pickle.load(file)\n",
    "\n",
    "with open(\"subcategories.pkl\", \"rb\") as file:\n",
    "    subcategories = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_prompt(row):\n",
    "    \"\"\"\n",
    "    Converts incident descriptions into structured prompts for the model.\n",
    "    \n",
    "    Args:\n",
    "        row (str): Raw incident description\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted prompt with instructions and context\n",
    "    \"\"\"\n",
    "    prompt_template = '''\n",
    "    You are provided with information provided by the victim about a cybersecurity crime, along with exhaustive lists of categories and sub-categories. Your task is to classify the crime into one of the categories and one of the sub-categories based on the provided information.\n",
    "\n",
    "    Details:\n",
    "    - **Crime Description**:\n",
    "    {crime}\n",
    "\n",
    "    - **Categories**:\n",
    "    {categories}\n",
    "\n",
    "    - **Sub-categories**:\n",
    "    {subcategories}\n",
    "\n",
    "    **Instructions**:\n",
    "    1. Based on the provided crime description, identify the most appropriate category and sub-category from the lists provided above.\n",
    "    2. If the information is insufficient or ambiguous to assign it into a specific category or subcategory, assign up to a maximum of three sub-categories and three categories that are most relevant to the context. Separate multiple categories or sub-categories using `' or '`.\n",
    "    3. Do not provide explanations or additional text; strictly follow the output format.\n",
    "\n",
    "    **Output Format**:\n",
    "    category: <respective_category> subcategory: <respective_subcategory>\n",
    "    '''\n",
    "\n",
    "    return prompt_template.format(crime=row, categories=categories, subcategories=subcategories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Prepares the dataset for model evaluation.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Raw dataset with incident descriptions\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed dataset with input_text and target_text\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df['input_text'] = data['crimeaditionalinfo'].apply(convert_to_prompt)\n",
    "    df['target_text'] = data.apply(lambda row: f\"category: {row['category']} subcategory: {row['sub_category']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "# Process test dataset\n",
    "raw_test_dataset = test_dataset.copy()\n",
    "prepro_test_dataset = preprocess_data(test_dataset)\n",
    "test_dataset = Dataset.from_pandas(prepro_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Loading and Inference Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fine-tuned model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('./fine_tuned_t5small').to('cuda')\n",
    "tokenizer = T5Tokenizer.from_pretrained('./fine_tuned_t5small')\n",
    "model.eval()\n",
    "\n",
    "def generate_text(inputs):\n",
    "    \"\"\"\n",
    "    Generates predictions for a batch of inputs.\n",
    "    \n",
    "    Args:\n",
    "        inputs (list): List of input texts\n",
    "        \n",
    "    Returns:\n",
    "        list: Generated predictions\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        inputs, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=1500\n",
    "    )\n",
    "    inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=1500)\n",
    "\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "def extract_details(text):\n",
    "    \"\"\"\n",
    "    Extracts category and subcategory from model output.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Model generated text\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Extracted (category, subcategory)\n",
    "    \"\"\"\n",
    "    pattern = r'category: (.*?) subcategory: (.*)'\n",
    "    match = re.match(pattern, text)\n",
    "    if match:\n",
    "        return tuple(item if item is not None else 'na' for item in match.groups())\n",
    "    return 'na', 'na'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inspecting the generation from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = test_dataset['target_text']\n",
    "test_input = test_dataset['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :\n",
      "\n",
      "\n",
      "    You are provided with information provided by the victim about a cybersecurity crime, along with exhaustive lists of categories and sub-categories. Your task is to classify the crime into one of the categories and one of the sub-categories based on the provided information.\n",
      "\n",
      "    Details:\n",
      "    - **Crime Description**:\n",
      "    spam message i recieve msg from unwanted number they say you take loan and today is repayment date but i did not take loani recieve text and whatsapp message any time for make repayment of loan but i did not take any loan\n",
      "\n",
      "    - **Categories**:\n",
      "    ['Online and Social Media Related Crime', 'Online Financial Fraud', 'Online Gambling  Betting', 'RapeGang Rape RGRSexually Abusive Content', 'Any Other Cyber Crime', 'Cyber Attack/ Dependent Crimes', 'Cryptocurrency Crime', 'Sexually Explicit Act', 'Sexually Obscene material', 'Hacking  Damage to computercomputer system etc', 'Cyber Terrorism', 'Child Pornography CPChild Sexual Abuse Material CSAM', 'Online Cyber Trafficking', 'Ransomware', 'Report Unlawful Content']\n",
      "\n",
      "    - **Sub-categories**:\n",
      "    ['Cyber Bullying  Stalking  Sexting', 'Fraud CallVishing', 'Online Gambling  Betting', 'Online Job Fraud', 'UPI Related Frauds', 'Internet Banking Related Fraud', 'sub-category of RapeGang Rape RGRSexually Abusive Content', 'Other', 'Profile Hacking Identity Theft', 'DebitCredit Card FraudSim Swap Fraud', 'EWallet Related Fraud', 'Data Breach/Theft', 'Cheating by Impersonation', 'Denial of Service (DoS)/Distributed Denial of Service (DDOS) attacks', 'FakeImpersonating Profile', 'Cryptocurrency Fraud', 'sub-category of Sexually Explicit Act', 'sub-category of Sexually Obscene material', 'Malware Attack', 'Business Email CompromiseEmail Takeover', 'Email Hacking', 'Hacking/Defacement', 'Unauthorised AccessData Breach', 'SQL Injection', 'Provocative Speech for unlawful acts', 'Ransomware Attack', 'Cyber Terrorism', 'sub-category of Child Pornography CPChild Sexual Abuse Material CSAM', 'Tampering with computer source documents', 'DematDepository Fraud', 'Online Trafficking', 'Online Matrimonial Fraud', 'Website DefacementHacking', 'Damage to computer computer systems etc', 'Impersonating Email', 'EMail Phishing', 'Ransomware', 'Intimidating Email', 'Against Interest of sovereignty or integrity of India']\n",
      "\n",
      "    **Instructions**:\n",
      "    1. Based on the provided crime description, identify the most appropriate category and sub-category from the lists provided above.\n",
      "    2. If the information is insufficient or ambiguous to assign it into a specific category or subcategory, assign up to a maximum of three sub-categories and three categories that are most relevant to the context. Separate multiple categories or sub-categories using `' or '`.\n",
      "    3. Do not provide explanations or additional text; strictly follow the output format.\n",
      "\n",
      "    **Output Format**:\n",
      "    category: <respective_category> subcategory: <respective_subcategory>\n",
      "    \n",
      "Expected Target :\n",
      "\n",
      "category: Online Financial Fraud subcategory: Fraud CallVishing\n"
     ]
    }
   ],
   "source": [
    "print(\"Input :\\n\")\n",
    "print(test_input[15])\n",
    "print(\"Expected Target :\\n\")\n",
    "print(test_target[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> category: Online Financial Fraud subcategory: Fraud CallVishing</s>\n"
     ]
    }
   ],
   "source": [
    "input_text = test_input[15]\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(input_ids, max_length=1500)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Processing and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test data: 100%|██████████| 222/222 [10:14<00:00,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# Process test data in batches\n",
    "batch_size = 128\n",
    "generated_details = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_input), batch_size), desc=\"Processing test data\"):\n",
    "    batch_inputs = test_input[i:i+batch_size]\n",
    "    generated_texts = generate_text(batch_inputs)\n",
    "    for generated_text in generated_texts:\n",
    "        generated_details.append(extract_details(generated_text))\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "test_predicted_df = pd.DataFrame(generated_details, columns=[\"category\", \"sub_category\"])\n",
    "test_target_df = raw_test_dataset[[\"category\", \"sub_category\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item-level Metrics:\n",
      "Accuracy: 0.4914\n",
      "Precision: 0.1154\n",
      "Recall: 0.0963\n",
      "F1-Score: 0.0953\n",
      "\n",
      "Category-level Metrics:\n",
      "Accuracy: 0.7399\n",
      "Precision: 0.1912\n",
      "Recall: 0.1465\n",
      "F1-Score: 0.1570\n",
      "\n",
      "Sub_category-level Metrics:\n",
      "Accuracy: 0.4954\n",
      "Precision: 0.1324\n",
      "Recall: 0.1096\n",
      "F1-Score: 0.1096\n"
     ]
    }
   ],
   "source": [
    "# Create combined predictions for overall metrics\n",
    "combined_pred = test_predicted_df[\"category\"] + \"_\" + test_predicted_df[\"sub_category\"]\n",
    "combined_true = test_target_df[\"category\"] + \"_\" + test_target_df[\"sub_category\"]\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Item-level\": {\n",
    "        \"Accuracy\": accuracy_score(combined_true, combined_pred),\n",
    "        \"Precision\": precision_score(combined_true, combined_pred, average=\"macro\", zero_division=0),\n",
    "        \"Recall\": recall_score(combined_true, combined_pred, average=\"macro\", zero_division=0),\n",
    "        \"F1-Score\": f1_score(combined_true, combined_pred, average=\"macro\", zero_division=0)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Individual column metrics\n",
    "for column in [\"category\", \"sub_category\"]:\n",
    "    metrics[f\"{column.capitalize()}-level\"] = {\n",
    "        \"Accuracy\": accuracy_score(test_target_df[column], test_predicted_df[column]),\n",
    "        \"Precision\": precision_score(test_target_df[column], test_predicted_df[column], average=\"macro\", zero_division=0),\n",
    "        \"Recall\": recall_score(test_target_df[column], test_predicted_df[column], average=\"macro\", zero_division=0),\n",
    "        \"F1-Score\": f1_score(test_target_df[column], test_predicted_df[column], average=\"macro\", zero_division=0)\n",
    "    }\n",
    "\n",
    "# Print metrics\n",
    "for level, scores in metrics.items():\n",
    "    print(f\"\\n{level} Metrics:\")\n",
    "    for metric, value in scores.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Highlights\n",
    "\n",
    "1. **Strong Category Classification:** The model achieves a robust 73.99% accuracy in identifying the main category of cybersecurity incidents, which is particularly impressive considering:\n",
    "\n",
    "    - The complexity of cybersecurity incidents\n",
    "    - The potential overlap between different categories\n",
    "    - The use of the smallest variant of the T5 model family\n",
    "\n",
    "2. **Balanced Performance:** The model maintains consistent performance across subcategories (49.54%) and combined item-level classification (49.14%), showing stable learning across different granularities.\n",
    "3. **Resource Efficiency:** These results were achieved using T5-small, which is the most lightweight variant of the T5 model family, making it:\n",
    "\n",
    "    - Computationally efficient\n",
    "    - Faster in inference time\n",
    "    - More suitable for deployment in resource-constrained environments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
